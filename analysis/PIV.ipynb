{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.registration import optical_flow_tvl1\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "video_folder = '/home/shichen/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good'\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(video_folder)\n",
    "\n",
    "# Filter to keep only .avi files\n",
    "videos = [f for f in files if f.endswith('.avi')]\n",
    "\n",
    "print(videos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.registration import optical_flow_tvl1\n",
    "from skimage import filters\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Read video\n",
    "cap = cv2.VideoCapture('/home/shichen/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/0_MT_1uL_correlation.avi')\n",
    "\n",
    "# Predefine the list of numbers to check\n",
    "check_numbers = np.arange(1, 101)  # Check numbers from 1 to 100\n",
    "\n",
    "# Prepare an empty list to store the correlation lengths\n",
    "correlation_lengths = []\n",
    "\n",
    "for num in check_numbers:\n",
    "    try:\n",
    "        # Insert the calculation logic here\n",
    "\n",
    "        # Assume 'correlation_length' is the result of the calculation\n",
    "        correlation_lengths.append(correlation_lengths)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for number {num}: {str(e)}\")\n",
    "\n",
    "# Print out the results\n",
    "for num, length in zip(check_numbers, correlation_lengths):\n",
    "    print(f\"Correlation length for number {num}: {length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.registration import optical_flow_tvl1\n",
    "from skimage import filters\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.registration import optical_flow_tvl1\n",
    "from skimage import filters\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Initial setup\n",
    "saveimg = False\n",
    "sample = '235_MT_correlation_15ul'\n",
    "vidpath = '/home/shichen/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/'\n",
    "vidname = vidpath + sample + '.avi'\n",
    "EdgeLength = 40\n",
    "smooth = True\n",
    "smooth_len = 10\n",
    "pxlen = .43\n",
    "vscale = 1\n",
    "tmin = 10\n",
    "tmax = 100\n",
    "delta_T = 1\n",
    "step = 5\n",
    "tseries = range(tmin, tmax+1, step)\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture(vidname)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"Could not open video file {vidname}\")\n",
    "\n",
    "# Define the range of the video we are interested in\n",
    "ret, frame1 = cap.read()\n",
    "yrange = range(851,1051)\n",
    "xrange = range(frame1.shape[1])\n",
    "\n",
    "# Get the total number of frames\n",
    "Ttot = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Read the initial frame\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 100)  # frame numbering in OpenCV starts from 0\n",
    "ret, frame1 = cap.read()\n",
    "\n",
    "# Convert the color image to grayscale\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Crop and normalize the image\n",
    "im1 = cv2.normalize(gray1[yrange, :][:, xrange], None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "print(\"Video has been successfully read and initial frame has been processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X1 and Y1 similar to your MATLAB code\n",
    "X1, Y1 = np.meshgrid(np.arange(EdgeLength / 2, len(xrange) - EdgeLength / 2, EdgeLength),\n",
    "                     np.arange(EdgeLength / 2, len(yrange) - EdgeLength / 2, EdgeLength))\n",
    "\n",
    "# Initialize correlation length array\n",
    "corr_len = np.zeros(len(tseries))\n",
    "\n",
    "# Loop over the time series\n",
    "for i, tt in enumerate(tseries):\n",
    "    # Read frames tt and tt+delta_T\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt)\n",
    "    _, frame1 = cap.read()\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt+delta_T)\n",
    "    _, frame2 = cap.read()\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "\n",
    "    # Normalize\n",
    "    im1 = cv2.normalize(gray1, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    im2 = cv2.normalize(gray2, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    # Compute the optical flow\n",
    "    flow = optical_flow_tvl1(im1, im2)\n",
    "    VX = -flow[..., 0] / delta_T\n",
    "    VY = -flow[..., 1] / delta_T\n",
    "\n",
    "    # Apply Gaussian smoothing if desired\n",
    "    if smooth:\n",
    "        VX = filters.gaussian(VX, sigma=smooth_len)\n",
    "        VY = filters.gaussian(VY, sigma=smooth_len)\n",
    "\n",
    "    # Subtract the mean\n",
    "    VX -= VX.mean()\n",
    "    VY -= VY.mean()\n",
    "\n",
    "    print(f\"Processed time step {tt}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the criteria for the ECC algorithm\n",
    "criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 100, 0.001)\n",
    "\n",
    "# Initialize the warp matrix with identity transformation\n",
    "warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "# Apply the ECC algorithm\n",
    "(cc, warp_matrix) = cv2.findTransformECC(im1, im2, warp_matrix, cv2.MOTION_EUCLIDEAN, criteria)\n",
    "\n",
    "# Use warpAffine to warp the second image\n",
    "im2_aligned = cv2.warpAffine(im2, warp_matrix, (im2.shape[1], im2.shape[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "# Now let's calculate the optical flow between the original and warped images\n",
    "flow = cv2.calcOpticalFlowFarneback(im1, im2_aligned, None, pyr_scale=0.5, levels=5, winsize=11, iterations=5, poly_n=5, poly_sigma=1.2, flags=0)\n",
    "\n",
    "VX = flow[..., 0]\n",
    "VY = flow[..., 1]\n",
    "\n",
    "# Create PX and PY by element-wise multiplication of im1 and VX, VY respectively\n",
    "PX = im1 * VX\n",
    "PY = im1 * VY\n",
    "\n",
    "print(f\"Shape of VX: {VX.shape}, Shape of VY: {VY.shape}\")\n",
    "print(f\"Shape of PX: {PX.shape}, Shape of PY: {PY.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "if smooth:\n",
    "    VX_smooth = gaussian_filter(VX, smooth_len)\n",
    "    VY_smooth = gaussian_filter(VY, smooth_len)\n",
    "    print(\"VX and VY have been smoothed successfully.\")\n",
    "else:\n",
    "    VX_smooth = VX\n",
    "    VY_smooth = VY\n",
    "    print(\"No smoothing applied.\")\n",
    "\n",
    "VX_mean_subtracted = VX_smooth - np.mean(VX_smooth)\n",
    "VY_mean_subtracted = VY_smooth - np.mean(VY_smooth)\n",
    "\n",
    "print(\"Mean subtracted from VX and VY successfully.\")\n",
    "\n",
    "PX = im1 * VX_mean_subtracted\n",
    "PY = im1 * VY_mean_subtracted\n",
    "\n",
    "print(\"PX and PY have been calculated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Resize and rescale UX and UY\n",
    "UX = cv2.resize(PX, (Y1.shape[1], X1.shape[0])) * vscale\n",
    "UY = cv2.resize(PY, (Y1.shape[1], X1.shape[0])) * vscale\n",
    "\n",
    "print(\"UX and UY have been resized and rescaled.\")\n",
    "\n",
    "# Step 8: Calculate the mean, smoothed data, and product of smoothed data\n",
    "PXmean = np.mean(PX, axis=0)\n",
    "PXsmth = gaussian_filter1d(PXmean, smooth_len)\n",
    "PXsmth = PXsmth / np.max(np.abs(PXsmth))\n",
    "\n",
    "PXprod = PXsmth[:-1] * PXsmth[1:]\n",
    "\n",
    "print(\"Calculated the mean, smoothed data, and product of smoothed data.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Find zero-crossings in PXprod\n",
    "PXzc = np.where(np.diff(np.sign(PXprod)))[0]\n",
    "\n",
    "print(\"Found zero-crossings in PXprod.\")\n",
    "\n",
    "# Step 10: Calculate the first difference of PXsmth\n",
    "PXd1 = np.diff(PXsmth, n=1)\n",
    "\n",
    "print(\"Calculated the first difference of PXsmth.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PXzc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Identify sinks\n",
    "PXsink = [ii for ii in PXzc if PXd1[ii]<0]\n",
    "\n",
    "print(f\"Identified {len(PXsink)} sinks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PXsink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Peaks:\", peaks)\n",
    "print(\"Wells:\", wells)\n",
    "# Step 13: Calculate peaks and wells\n",
    "peak_indices = []\n",
    "well_indices = []\n",
    "for ss in range(len(PXsrc)-1):\n",
    "    range_min, range_max = PXsrc[ss] - 1, PXsrc[ss+1] - 1\n",
    "    if range_min < range_max:\n",
    "        peak_indices.append(np.argmax(PXsmth[range_min:range_max+1]) + range_min)\n",
    "        well_indices.append(np.argmin(PXsmth[range_min:range_max+1]) + range_min)\n",
    "\n",
    "print(f\"Identified {len(peak_indices)} peak indices and {len(well_indices)} well indices.\")\n",
    "# Step 14: Calculate gaps\n",
    "gaps = [well_indices[ii] - peak_indices[ii] for ii in range(len(peak_indices)) if well_indices[ii] - peak_indices[ii] > 0]\n",
    "\n",
    "print(f\"Identified {len(gaps)} gaps.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.registration import optical_flow_tvl1\n",
    "from skimage import filters\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def open_video(vidname):\n",
    "    cap = cv2.VideoCapture(vidname)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(f\"Could not open video file {vidname}\")\n",
    "    return cap\n",
    "\n",
    "def process_initial_frame(cap, xrange, yrange):\n",
    "    ret, frame1 = cap.read()\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    im1 = cv2.normalize(gray1[yrange, :][:, xrange], None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    return im1\n",
    "\n",
    "def compute_optical_flow(cap, tt, delta_T, yrange, xrange, smooth, smooth_len):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt)\n",
    "    _, frame1 = cap.read()\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt+delta_T)\n",
    "    _, frame2 = cap.read()\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "    im1 = cv2.normalize(gray1, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    im2 = cv2.normalize(gray2, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    flow = optical_flow_tvl1(im1, im2)\n",
    "    VX = -flow[..., 0] / delta_T\n",
    "    VY = -flow[..., 1] / delta_T\n",
    "    if smooth:\n",
    "        VX = filters.gaussian(VX, sigma=smooth_len)\n",
    "        VY = filters.gaussian(VY, sigma=smooth_len)\n",
    "    VX -= VX.mean()\n",
    "    VY -= VY.mean()\n",
    "    return VX, VY\n",
    "\n",
    "def compute_PX_and_PY(im1, VX, VY):\n",
    "    PX = im1 * VX\n",
    "    PY = im1 * VY\n",
    "    return PX, PY\n",
    "\n",
    "def compute_correlation_lengths(PX, PXsrc, PXsmth, pxlen):\n",
    "    peaks = []\n",
    "    wells = []\n",
    "    for ss in range(len(PXsrc)-1):\n",
    "        range_min, range_max = PXsrc[ss], PXsrc[ss+1]\n",
    "        if range_min >= range_max:\n",
    "            print(f\"Empty range at index {ss} with range_min: {range_min}, range_max: {range_max}\")\n",
    "            continue\n",
    "        peaks.append(np.argmax(PXsmth[range_min:range_max+1]))\n",
    "        wells.append(np.argmin(PXsmth[range_min:range_max+1]))\n",
    "    gaps = [wells[ii] - peaks[ii] for ii in range(len(peaks)) if wells[ii] - peaks[ii] > 0]\n",
    "    corr_len = np.mean(gaps) * pxlen\n",
    "    return corr_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = '235_MT_correlation_15ul'\n",
    "vidpath = '/home/shichen/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/'\n",
    "vidname = vidpath + sample + '.avi'\n",
    "\n",
    "cap = open_video(vidname)\n",
    "\n",
    "im1 = process_initial_frame(cap, xrange, yrange)\n",
    "\n",
    "X1, Y1 = np.meshgrid(np.arange(EdgeLength / 2, len(xrange) - EdgeLength / 2, EdgeLength),\n",
    "                     np.arange(EdgeLength / 2, len(yrange) - EdgeLength / 2, EdgeLength))\n",
    "\n",
    "corr_len = np.zeros(len(tseries))\n",
    "\n",
    "for i, tt in enumerate(tseries):\n",
    "    VX, VY = compute_optical_flow(cap, tt, delta_T, yrange, xrange, smooth, smooth_len)\n",
    "    PX, PY = compute_PX_and_PY(im1, VX, VY)\n",
    "    corr_len[i] = compute_correlation_lengths(PX, PXsrc, PXsmth, pxlen)\n",
    "    print(f\"Correlation length at time step {tt}: {corr_len[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = read_and_preprocess_frame(cap, 100, yrange, xrange)\n",
    "\n",
    "# Loop over the time series\n",
    "for tt in tseries:\n",
    "    # Read frames tt and tt+delta_T\n",
    "    im1 = read_and_preprocess_frame(cap, tt, yrange, xrange)\n",
    "    im2 = read_and_preprocess_frame(cap, tt+delta_T, yrange, xrange)\n",
    "\n",
    "    # Compute the optical flow\n",
    "    VX, VY = compute_optical_flow(im1, im2)\n",
    "\n",
    "    # Smooth and zero mean\n",
    "    VX, VY = smooth_and_zero_mean(VX, VY, smooth_len)\n",
    "\n",
    "    # Compute PX and PY\n",
    "    PX, PY = compute_PX_and_PY(im1, VX, VY)\n",
    "\n",
    "    # Compute correlation lengths\n",
    "    corr_len = compute_correlation_lengths(PX, PXsrc, PXsmth, pxlen)\n",
    "    print(f\"Correlation length at time step {tt}: {corr_len}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 15: Plot the correlation length\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(tseries, corr_len, linewidth=5)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Correlation Length / um')\n",
    "plt.grid(True)\n",
    "plt.title('Correlation Length vs Time')\n",
    "plt.savefig('CorrLength.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Set the parameters\n",
    "filename = '/home/shichen/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/235_MT_correlation_15ul.avi'  # your video file\n",
    "yrange = slice(851, 1050)\n",
    "xrange = slice(1, 2048)  # change to match your video's width\n",
    "tmin = 10\n",
    "tmax = 100\n",
    "delta_T = 1\n",
    "step = 5\n",
    "tseries = range(tmin, tmax+1, step)\n",
    "pxlen = .43\n",
    "smooth = True\n",
    "smooth_len = 10\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(filename)\n",
    "\n",
    "# Initialize an empty list to store correlation lengths\n",
    "corr_len = []\n",
    "\n",
    "# Process each pair of frames\n",
    "for tt in tseries:\n",
    "    # Read and preprocess the frames\n",
    "    im1 = read_and_preprocess_frame(cap, tt, yrange, xrange)\n",
    "    im2 = read_and_preprocess_frame(cap, tt + delta_T, yrange, xrange)\n",
    "    \n",
    "    # Compute the optical flow\n",
    "    VX, VY = compute_optical_flow(im1, im2)\n",
    "    \n",
    "    # Smooth and zero-mean the vectors\n",
    "    VX, VY = smooth_and_zero_mean(VX, VY, smooth_len)\n",
    "    \n",
    "    # Compute PX and PY\n",
    "    PX, PY = compute_PX_and_PY(im1, VX, VY)\n",
    "\n",
    "    # Smooth the PX array for peak detection\n",
    "    PXsmth = gaussian_filter1d(PX, 10, mode='constant', cval=0.0)\n",
    "    \n",
    "    # Find sources, sinks, and gaps\n",
    "    PXsrc, PXsink, gaps = find_sources_sinks_and_gaps(PX, xrange, PXsmth)\n",
    "    \n",
    "    # Compute the correlation lengths\n",
    "    Lx = compute_correlation_lengths(PX, PXsrc, PXsmth, pxlen)\n",
    "    \n",
    "    # Append the correlation length to the list\n",
    "    corr_len.append(Lx)\n",
    "\n",
    "    # Print the correlation lengths\n",
    "    print(f\"Correlation lengths for frame {tt} to {tt+delta_T}: Lx = {Lx}\")\n",
    "    \n",
    "# Close the video file\n",
    "cap.release()\n",
    "\n",
    "# At this point, corr_len contains the correlation lengths for all frame pairs\n",
    "# You can save it to a file or plot it as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.registration import optical_flow_tvl1\n",
    "from skimage import filters\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Initial setup\n",
    "saveimg = False\n",
    "sample = '235_MT_correlation_15ul'\n",
    "vidpath = '/home/shichen/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/'\n",
    "vidname = vidpath + sample + '.avi'\n",
    "EdgeLength = 40\n",
    "smooth = True\n",
    "smooth_len = 10\n",
    "pxlen = .43\n",
    "vscale = 1\n",
    "tmin = 10\n",
    "tmax = 100\n",
    "delta_T = 1\n",
    "step = 5\n",
    "tseries = range(tmin, tmax+1, step)\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture(vidname)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"Could not open video file {vidname}\")\n",
    "\n",
    "# Define the range of the video we are interested in\n",
    "ret, frame1 = cap.read()\n",
    "yrange = range(851,1051)\n",
    "xrange = range(frame1.shape[1])\n",
    "\n",
    "# Get the total number of frames\n",
    "Ttot = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Read the initial frame\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 100)  # frame numbering in OpenCV starts from 0\n",
    "ret, frame1 = cap.read()\n",
    "\n",
    "# Convert the color image to grayscale\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Crop and normalize the image\n",
    "im1 = cv2.normalize(gray1[yrange, :][:, xrange], None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "print(\"Video has been successfully read and initial frame has been processed.\")\n",
    "\n",
    "\n",
    "# Define X1 and Y1 similar to your MATLAB code\n",
    "X1, Y1 = np.meshgrid(np.arange(EdgeLength / 2, len(xrange) - EdgeLength / 2, EdgeLength),\n",
    "                     np.arange(EdgeLength / 2, len(yrange) - EdgeLength / 2, EdgeLength))\n",
    "\n",
    "# Initialize correlation length array\n",
    "corr_len = np.zeros(len(tseries))\n",
    "\n",
    "# Loop over the time series\n",
    "for i, tt in enumerate(tseries):\n",
    "    # Read frames tt and tt+delta_T\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt)\n",
    "    _, frame1 = cap.read()\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt+delta_T)\n",
    "    _, frame2 = cap.read()\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "\n",
    "    # Normalize\n",
    "    im1 = cv2.normalize(gray1, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    im2 = cv2.normalize(gray2, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    # Compute the optical flow\n",
    "    flow = optical_flow_tvl1(im1, im2)\n",
    "    VX = -flow[..., 0] / delta_T\n",
    "    VY = -flow[..., 1] / delta_T\n",
    "\n",
    "    # Apply Gaussian smoothing if desired\n",
    "    if smooth:\n",
    "        VX = filters.gaussian(VX, sigma=smooth_len)\n",
    "        VY = filters.gaussian(VY, sigma=smooth_len)\n",
    "\n",
    "    # Subtract the mean\n",
    "    VX -= VX.mean()\n",
    "    VY -= VY.mean()\n",
    "\n",
    "    print(f\"Processed time step {tt}.\")\n",
    "\n",
    "\n",
    "# Define the criteria for the ECC algorithm\n",
    "criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 100, 0.001)\n",
    "\n",
    "# Initialize the warp matrix with identity transformation\n",
    "warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "# Apply the ECC algorithm\n",
    "(cc, warp_matrix) = cv2.findTransformECC(im1, im2, warp_matrix, cv2.MOTION_EUCLIDEAN, criteria)\n",
    "\n",
    "# Use warpAffine to warp the second image\n",
    "im2_aligned = cv2.warpAffine(im2, warp_matrix, (im2.shape[1], im2.shape[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "# Now let's calculate the optical flow between the original and warped images\n",
    "flow = cv2.calcOpticalFlowFarneback(im1, im2_aligned, None, pyr_scale=0.5, levels=5, winsize=11, iterations=5, poly_n=5, poly_sigma=1.2, flags=0)\n",
    "\n",
    "VX = flow[..., 0]\n",
    "VY = flow[..., 1]\n",
    "\n",
    "# Create PX and PY by element-wise multiplication of im1 and VX, VY respectively\n",
    "PX = im1 * VX\n",
    "PY = im1 * VY\n",
    "\n",
    "print(f\"Shape of VX: {VX.shape}, Shape of VY: {VY.shape}\")\n",
    "print(f\"Shape of PX: {PX.shape}, Shape of PY: {PY.shape}\")\n",
    "\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "if smooth:\n",
    "    VX_smooth = gaussian_filter(VX, smooth_len)\n",
    "    VY_smooth = gaussian_filter(VY, smooth_len)\n",
    "    print(\"VX and VY have been smoothed successfully.\")\n",
    "else:\n",
    "    VX_smooth = VX\n",
    "    VY_smooth = VY\n",
    "    print(\"No smoothing applied.\")\n",
    "\n",
    "VX_mean_subtracted = VX_smooth - np.mean(VX_smooth)\n",
    "VY_mean_subtracted = VY_smooth - np.mean(VY_smooth)\n",
    "\n",
    "print(\"Mean subtracted from VX and VY successfully.\")\n",
    "\n",
    "PX = im1 * VX_mean_subtracted\n",
    "PY = im1 * VY_mean_subtracted\n",
    "\n",
    "print(\"PX and PY have been calculated.\")\n",
    "\n",
    "# Step 7: Resize and rescale UX and UY\n",
    "UX = cv2.resize(PX, (Y1.shape[1], X1.shape[0])) * vscale\n",
    "UY = cv2.resize(PY, (Y1.shape[1], X1.shape[0])) * vscale\n",
    "\n",
    "print(\"UX and UY have been resized and rescaled.\")\n",
    "\n",
    "# Step 8: Calculate the mean, smoothed data, and product of smoothed data\n",
    "PXmean = np.mean(PX, axis=0)\n",
    "PXsmth = gaussian_filter1d(PXmean, smooth_len)\n",
    "PXsmth = PXsmth / np.max(np.abs(PXsmth))\n",
    "\n",
    "PXprod = PXsmth[:-1] * PXsmth[1:]\n",
    "\n",
    "print(\"Calculated the mean, smoothed data, and product of smoothed data.\")\n",
    "\n",
    "\n",
    "# Step 9: Find zero-crossings in PXprod\n",
    "PXzc = np.where(np.diff(np.sign(PXprod)))[0]\n",
    "\n",
    "print(\"Found zero-crossings in PXprod.\")\n",
    "\n",
    "# Step 10: Calculate the first difference of PXsmth\n",
    "PXd1 = np.diff(PXsmth, n=1)\n",
    "\n",
    "print(\"Calculated the first difference of PXsmth.\")\n",
    "\n",
    "\n",
    "# Step 11: Identify sinks\n",
    "PXsink = [ii for ii in PXzc if PXd1[ii]<0]\n",
    "\n",
    "# Calculate the correlation distance between pixels\n",
    "if len(PXsink) > 1:\n",
    "    corr_distance = np.mean(np.diff(PXsink))\n",
    "else:\n",
    "    # If there's only one sink, correlation length is the width of the rectangle\n",
    "    corr_distance = EdgeLength * pxlen\n",
    "\n",
    "corr_len[tp] = corr_distance\n",
    "\n",
    "print(f\"Identified {len(PXsink)} sinks.\")\n",
    "\n",
    "\n",
    "# Step 13: Calculate peaks and wells\n",
    "peak_indices = []\n",
    "well_indices = []\n",
    "for ss in range(len(PXsrc)-1):\n",
    "    range_min, range_max = PXsrc[ss] - 1, PXsrc[ss+1] - 1\n",
    "    if range_min < range_max:\n",
    "        peak_indices.append(np.argmax(PXsmth[range_min:range_max+1]) + range_min)\n",
    "        well_indices.append(np.argmin(PXsmth[range_min:range_max+1]) + range_min)\n",
    "\n",
    "print(f\"Identified {len(peak_indices)} peak indices and {len(well_indices)} well indices.\")\n",
    "# Step 14: Calculate gaps\n",
    "gaps = [well_indices[ii] - peak_indices[ii] for ii in range(len(peak_indices)) if well_indices[ii] - peak_indices[ii] > 0]\n",
    "\n",
    "print(f\"Identified {len(gaps)} gaps.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.registration import optical_flow_tvl1\n",
    "from skimage import filters\n",
    "from scipy.ndimage import gaussian_filter, gaussian_filter1d\n",
    "\n",
    "# Initialize an array to store correlation lengths for all pairs of frames\n",
    "all_corr_len = np.zeros((len(tseries), len(tseries)))\n",
    "\n",
    "# Initial setup\n",
    "saveimg = False\n",
    "sample = '235_MT_correlation_15ul'\n",
    "vidpath = '/home/shichen/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/'\n",
    "vidname = vidpath + sample + '.avi'\n",
    "EdgeLength = 40\n",
    "smooth = True\n",
    "smooth_len = 10\n",
    "pxlen = .43\n",
    "vscale = 1\n",
    "tmin = 10\n",
    "tmax = 100\n",
    "delta_T = 1\n",
    "step = 5\n",
    "tseries = range(tmin, tmax+1, step)\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture(vidname)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"Could not open video file {vidname}\")\n",
    "\n",
    "# Define the range of the video we are interested in\n",
    "ret, frame1 = cap.read()\n",
    "yrange = range(851, 1051)\n",
    "xrange = range(frame1.shape[1])\n",
    "\n",
    "# Nested loop to calculate correlation lengths for all pairs of frames\n",
    "for i, tt1 in enumerate(tseries):\n",
    "    for j, tt2 in enumerate(tseries):\n",
    "        # Skip if the two frames are the same\n",
    "        if i == j:\n",
    "            continue\n",
    "\n",
    "        # Read frames tt1 and tt2\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, tt1)\n",
    "        _, frame1 = cap.read()\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, tt2)\n",
    "        _, frame2 = cap.read()\n",
    "\n",
    "        # Convert frames to grayscale and normalize\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "        im1 = cv2.normalize(gray1, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        im2 = cv2.normalize(gray2, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "        # Define X1 and Y1 similar to your MATLAB code\n",
    "        X1, Y1 = np.meshgrid(np.arange(EdgeLength / 2, len(xrange) - EdgeLength / 2, EdgeLength),\n",
    "                             np.arange(EdgeLength / 2, len(yrange) - EdgeLength / 2, EdgeLength))\n",
    "\n",
    "        # Initialize correlation length array\n",
    "        corr_len = np.zeros(len(tseries))\n",
    "\n",
    "        # Loop over the time series\n",
    "        for i, tt in enumerate(tseries):\n",
    "            # Read frames tt and tt+delta_T\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, tt)\n",
    "            _, frame1 = cap.read()\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, tt+delta_T)\n",
    "            _, frame2 = cap.read()\n",
    "\n",
    "            # Convert to grayscale\n",
    "            gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "            gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "\n",
    "            # Normalize\n",
    "            im1 = cv2.normalize(gray1, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "            im2 = cv2.normalize(gray2, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "            # Compute the optical flow\n",
    "            flow = optical_flow_tvl1(im1, im2)\n",
    "            VX = -flow[..., 0] / delta_T\n",
    "            VY = -flow[..., 1] / delta_T\n",
    "\n",
    "            # Apply Gaussian smoothing if desired\n",
    "            if smooth:\n",
    "                VX = filters.gaussian(VX, sigma=smooth_len)\n",
    "                VY = filters.gaussian(VY, sigma=smooth_len)\n",
    "\n",
    "            # Subtract the mean\n",
    "            VX -= VX.mean()\n",
    "            VY -= VY.mean()\n",
    "\n",
    "            print(f\"Processed time step {tt}.\")\n",
    "\n",
    "        # Define the criteria for the ECC algorithm\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 100, 0.001)\n",
    "\n",
    "        # Initialize the warp matrix with identity transformation\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "        # Apply the ECC algorithm\n",
    "        (cc, warp_matrix) = cv2.findTransformECC(im1, im2, warp_matrix, cv2.MOTION_EUCLIDEAN, criteria)\n",
    "\n",
    "        # Use warpAffine to warp the second image\n",
    "        im2_aligned = cv2.warpAffine(im2, warp_matrix, (im2.shape[1], im2.shape[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "        # Now let's calculate the optical flow between the original and warped images\n",
    "        flow = cv2.calcOpticalFlowFarneback(im1, im2_aligned, None, pyr_scale=0.5, levels=5, winsize=11, iterations=5, poly_n=5, poly_sigma=1.2, flags=0)\n",
    "\n",
    "        VX = flow[..., 0]\n",
    "        VY = flow[..., 1]\n",
    "\n",
    "        # Create PX and PY by element-wise multiplication of im1 and VX, VY respectively\n",
    "        PX = im1 * VX\n",
    "        PY = im1 * VY\n",
    "\n",
    "        print(f\"Shape of VX: {VX.shape}, Shape of VY: {VY.shape}\")\n",
    "        print(f\"Shape of PX: {PX.shape}, Shape of PY: {PY.shape}\")\n",
    "\n",
    "        if smooth:\n",
    "            VX_smooth = gaussian_filter(VX, smooth_len)\n",
    "            VY_smooth = gaussian_filter(VY, smooth_len)\n",
    "            print(\"VX and VY have been smoothed successfully.\")\n",
    "        else:\n",
    "            VX_smooth = VX\n",
    "            VY_smooth = VY\n",
    "            print(\"No smoothing applied.\")\n",
    "\n",
    "        VX_mean_subtracted = VX_smooth - np.mean(VX_smooth)\n",
    "        VY_mean_subtracted = VY_smooth - np.mean(VY_smooth)\n",
    "\n",
    "        print(\"Mean subtracted from VX and VY successfully.\")\n",
    "\n",
    "        PX = im1 * VX_mean_subtracted\n",
    "        PY = im1 * VY_mean_subtracted\n",
    "\n",
    "        print(\"PX and PY have been calculated.\")\n",
    "\n",
    "        # Step 7: Resize and rescale UX and UY\n",
    "        UX = cv2.resize(PX, (Y1.shape[1], X1.shape[0])) * vscale\n",
    "        UY = cv2.resize(PY, (Y1.shape[1], X1.shape[0])) * vscale\n",
    "\n",
    "        print(\"UX and UY have been resized and rescaled.\")\n",
    "\n",
    "        # Step 8: Calculate the mean, smoothed data, and product of\n",
    "        PXmean = np.mean(PX, axis=0)\n",
    "        PXsmth = gaussian_filter1d(PXmean, smooth_len)\n",
    "        PXsmth = PXsmth / np.max(np.abs(PXsmth))\n",
    "\n",
    "        PXprod = PXsmth[:-1] * PXsmth[1:]\n",
    "\n",
    "        print(\"Calculated the mean, smoothed data, and product of smoothed data.\")\n",
    "\n",
    "        # Step 9: Find zero-crossings in PXprod\n",
    "        PXzc = np.where(np.diff(np.sign(PXprod)))[0]\n",
    "\n",
    "        print(\"Found zero-crossings in PXprod.\")\n",
    "\n",
    "        # Step 10: Calculate the first difference of PXsmth\n",
    "        PXd1 = np.diff(PXsmth, n=1)\n",
    "\n",
    "        print(\"Calculated the first difference of PXsmth.\")\n",
    "\n",
    "        # Step 11: Identify sinks\n",
    "        PXsink = [ii for ii in PXzc if PXd1[ii] < 0]\n",
    "\n",
    "        # Calculate the correlation distance between pixels\n",
    "        if len(PXsink) > 1:\n",
    "            corr_distance = np.mean(np.diff(PXsink))\n",
    "        else:\n",
    "            # If there's only one sink, correlation length is the width of the rectangle\n",
    "            corr_distance = EdgeLength * pxlen\n",
    "\n",
    "        corr_len[i] = corr_distance\n",
    "\n",
    "        print(f\"Identified {len(PXsink)} sinks.\")\n",
    "\n",
    "        # Step 12: Identify sources\n",
    "        PXsrc = set(PXzc) - set(PXsink)\n",
    "        PXsrc = [1] + list(PXsrc) + [max(xrange)]\n",
    "\n",
    "        print(f\"Identified {len(PXsrc)} sources.\")\n",
    "\n",
    "        # Step 13: Calculate peaks and wells\n",
    "        peak_indices = []\n",
    "        well_indices = []\n",
    "        for ss in range(len(PXsrc) - 1):\n",
    "            range_min, range_max = PXsrc[ss] - 1, PXsrc[ss + 1] - 1\n",
    "            if range_min < range_max:\n",
    "                peak_indices.append(np.argmax(PXsmth[range_min:range_max + 1]) + range_min)\n",
    "                well_indices.append(np.argmin(PXsmth[range_min:range_max + 1]) + range_min)\n",
    "\n",
    "        print(f\"Identified {len(peak_indices)} peak indices and {len(well_indices)} well indices.\")\n",
    "        # Step 14: Calculate gaps\n",
    "        gaps = [well_indices[ii] - peak_indices[ii] for ii in range(len(peak_indices)) if well_indices[ii] - peak_indices[ii] > 0]\n",
    "\n",
    "        print(f\"Identified {len(gaps)} gaps.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.registration import optical_flow_tvl1\n",
    "from skimage import filters\n",
    "from scipy.ndimage import gaussian_filter, gaussian_filter1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame, xrange, yrange):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "    return cv2.normalize(gray, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "def get_flow(im1, im2, delta_T, smooth=False, smooth_len=10):\n",
    "    flow = optical_flow_tvl1(im1, im2)\n",
    "    VX = -flow[..., 0] / delta_T\n",
    "    VY = -flow[..., 1] / delta_T\n",
    "\n",
    "    if smooth:\n",
    "        VX = filters.gaussian(VX, sigma=smooth_len)\n",
    "        VY = filters.gaussian(VY, sigma=smooth_len)\n",
    "\n",
    "    VX -= VX.mean()\n",
    "    VY -= VY.mean()\n",
    "\n",
    "    return VX, VY\n",
    "def get_corr_distance(PX, smooth_len, pxlen, EdgeLength):\n",
    "    PXmean = np.mean(PX, axis=0)\n",
    "    PXsmth = gaussian_filter1d(PXmean, smooth_len)\n",
    "    PXsmth = PXsmth / np.max(np.abs(PXsmth))\n",
    "    PXprod = PXsmth[:-1] * PXsmth[1:]\n",
    "    PXzc = np.where(np.diff(np.sign(PXprod)))[0]\n",
    "    PXd1 = np.diff(PXsmth, n=1)\n",
    "    PXsink = [ii for ii in PXzc if PXd1[ii] < 0]\n",
    "\n",
    "    if len(PXsink) > 1:\n",
    "        corr_distance = np.mean(np.diff(PXsink))\n",
    "    else:\n",
    "        corr_distance = EdgeLength * pxlen\n",
    "\n",
    "    return corr_distance\n",
    "def get_correlation_len(tseries, cap, xrange, yrange, delta_T, EdgeLength, smooth, smooth_len, pxlen, vscale):\n",
    "    all_corr_len = np.zeros(len(tseries))\n",
    "    \n",
    "    tp = 0\n",
    "    for tt in tseries:\n",
    "        tp += 1\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, tt)\n",
    "        _, frame1 = cap.read()\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, tt+delta_T)\n",
    "        _, frame2 = cap.read()\n",
    "\n",
    "        im1 = process_frame(frame1, xrange, yrange)\n",
    "        im2 = process_frame(frame2, xrange, yrange)\n",
    "\n",
    "        # image registration\n",
    "        moved, warp_matrix = cv2.findTransformECC(im1, im2, np.eye(2, 3, dtype=np.float32), cv2.MOTION_EUCLIDEAN)\n",
    "        warp_matrix[0, 2] /= delta_T\n",
    "        warp_matrix[1, 2] /= delta_T\n",
    "        \n",
    "        # Smoothing\n",
    "        if smooth:\n",
    "            warp_matrix[0, 2] = gaussian_filter(warp_matrix[0, 2], smooth_len)\n",
    "            warp_matrix[1, 2] = gaussian_filter(warp_matrix[1, 2], smooth_len)\n",
    "        \n",
    "        # Subtract mean\n",
    "        warp_matrix[0, 2] -= np.mean(warp_matrix[0, 2])\n",
    "        warp_matrix[1, 2] -= np.mean(warp_matrix[1, 2])\n",
    "        \n",
    "        # Calculate P vectors\n",
    "        PX = im1 * warp_matrix[0, 2]\n",
    "        PY = im1 * warp_matrix[1, 2]\n",
    "\n",
    "        # Rescale\n",
    "        UX = vscale * cv2.resize(PX, (len(xrange), len(yrange)))\n",
    "        UY = vscale * cv2.resize(PY, (len(xrange), len(yrange)))\n",
    "\n",
    "        # Smooth the data and find zero-crossings\n",
    "        PXmean = np.mean(PX, axis=0)\n",
    "        PXsmth = gaussian_filter(PXmean, smooth_len)\n",
    "        PXsmth = PXsmth / np.max(np.abs(PXsmth))\n",
    "        PXprod = PXsmth[:-1] * PXsmth[1:]\n",
    "        PXzc = np.where(PXprod<0)[0]\n",
    "        \n",
    "        # Find sink points\n",
    "        PXd1 = np.diff(PXsmth)\n",
    "        PXsink = [ii for ii in PXzc if PXd1[ii] < 0]\n",
    "\n",
    "        # Find source points\n",
    "        PXsrc = list(set(PXzc) - set(PXsink))\n",
    "        PXsrc = [min(xrange)] + PXsrc + [max(xrange)]\n",
    "\n",
    "        # Find peaks and wells\n",
    "        peaks = []\n",
    "        wells = []\n",
    "        for ss in range(len(PXsrc)-1):\n",
    "            peak = np.max(PXsmth[PXsrc[ss]:PXsrc[ss+1]])\n",
    "            well = np.min(PXsmth[PXsrc[ss]:PXsrc[ss+1]])\n",
    "            peaks.append(peak)\n",
    "            wells.append(well)\n",
    "        \n",
    "        # Calculate correlation length\n",
    "        gaps = [well - peak for well, peak in zip(wells, peaks) if well - peak > 0]\n",
    "        corr_len = pxlen * np.mean(gaps)\n",
    "\n",
    "        all_corr_len[tp] = corr_len\n",
    "        \n",
    "    return all_corr_len\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup\n",
    "saveimg = False\n",
    "sample = '235_MT_correlation_15ul'\n",
    "vidpath = '/home/shichen/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/'\n",
    "vidname = vidpath + sample + '.avi'\n",
    "EdgeLength = 40\n",
    "smooth = 1\n",
    "smooth_len = 10\n",
    "pxlen = .43\n",
    "\n",
    "delta_T = 1\n",
    "vscale = 1\n",
    "tseries = list(range(10, 101, 5))\n",
    "\n",
    "cap = cv2.VideoCapture(vidname)\n",
    "# read a frame from the video to get its dimensions\n",
    "ret, frame = cap.read()\n",
    "height, width, _ = frame.shape\n",
    "\n",
    "# define xrange and yrange based on the dimensions of the video\n",
    "xrange = range(width)\n",
    "yrange = range(851, min(1051, height)) \n",
    "\n",
    "all_corr_len = get_correlation_len(tseries, cap, xrange, yrange, delta_T, EdgeLength, smooth, smooth_len, pxlen, vscale)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tseries, all_corr_len, linewidth=5)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Correlation Length / um')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an array to store correlation lengths for all pairs of frames\n",
    "all_corr_len = np.zeros((len(tseries), len(tseries)))\n",
    "\n",
    "# Nested loop to calculate correlation lengths for all pairs of frames\n",
    "for i, tt1 in enumerate(tseries):\n",
    "    for j, tt2 in enumerate(tseries):\n",
    "        if i == j:\n",
    "            continue\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, tt1)\n",
    "        _, frame1 = cap.read()\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, tt2)\n",
    "        _, frame2 = cap.read()\n",
    "\n",
    "        im1 = process_frame(frame1, xrange, yrange)\n",
    "        im2 = process_frame(frame2, xrange, yrange)\n",
    "\n",
    "        corr_len = get_correlation_len(tseries, cap, xrange, yrange, delta_T, EdgeLength, smooth, smooth_len, pxlen, vscale)\n",
    "        all_corr_len[i, j] = corr_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.registration import optical_flow_tvl1\n",
    "from skimage import filters\n",
    "from scipy.ndimage import gaussian_filter, gaussian_filter1d\n",
    "\n",
    "# Initial setup\n",
    "saveimg = False\n",
    "sample = '235_MT_correlation_15ul'\n",
    "vidpath = '/home/shichen/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/'\n",
    "vidname = vidpath + sample + '.avi'\n",
    "EdgeLength = 40\n",
    "smooth = True\n",
    "smooth_len = 10\n",
    "pxlen = .43\n",
    "vscale = 1\n",
    "tmin = 10\n",
    "tmax = 100\n",
    "delta_T = 1\n",
    "step = 5\n",
    "tseries = range(tmin, tmax+1, step)\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture(vidname)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"Could not open video file {vidname}\")\n",
    "\n",
    "# Define the range of the video we are interested in\n",
    "ret, frame1 = cap.read()\n",
    "yrange = range(851, 1051)\n",
    "xrange = range(frame1.shape[1])\n",
    "\n",
    "# Initialize correlation length array\n",
    "corr_len = np.zeros(len(tseries))\n",
    "\n",
    "# Loop over the time series\n",
    "for i, tt in enumerate(tseries):\n",
    "    # Read frames tt and tt+delta_T\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt)\n",
    "    _, frame1 = cap.read()\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt+delta_T)\n",
    "    _, frame2 = cap.read()\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "\n",
    "    # Normalize\n",
    "    im1 = cv2.normalize(gray1, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    im2 = cv2.normalize(gray2, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    # Compute the optical flow\n",
    "    flow = optical_flow_tvl1(im1, im2)\n",
    "    flow = np.transpose(flow, (1, 2, 0)) # Transpose the flow to have shape (200, 2048, 2)\n",
    "    VX = -flow[..., 0] / delta_T\n",
    "    VY = -flow[..., 1] / delta_T\n",
    "    print(\"Optical flow (Python):\")\n",
    "    print(flow)\n",
    "\n",
    "\n",
    "    # Apply Gaussian smoothing if desired\n",
    "    if smooth:\n",
    "        VX = filters.gaussian(VX, sigma=smooth_len)\n",
    "        VY = filters.gaussian(VY, sigma=smooth_len)\n",
    "\n",
    "    # Subtract the mean\n",
    "    VX -= VX.mean()\n",
    "    VY -= VY.mean()\n",
    "\n",
    "    # ... Continue with the rest of your original code here\n",
    "    # Continue from your last piece of code...\n",
    "\n",
    "    # Calculate products\n",
    "    PX = im1 * VX\n",
    "    PY = im1 * VY\n",
    "    print(\"Products (Python):\")\n",
    "    print(PX)\n",
    "    print(PY)\n",
    "\n",
    "    # Resize to the original image's size\n",
    "    UX = cv2.resize(PX, (len(xrange), len(yrange)))\n",
    "    UY = cv2.resize(PY, (len(xrange), len(yrange)))\n",
    "\n",
    "    # Compute smoothed version of PX\n",
    "    PXmean = np.mean(PX, axis=1)\n",
    "    PXsmth = gaussian_filter1d(PXmean, smooth_len)\n",
    "    PXsmth = PXsmth / np.abs(PXsmth).max()\n",
    "\n",
    "    # Find zero-crossings\n",
    "    PXprod = PXsmth[:-1] * PXsmth[1:]\n",
    "    PXzc = np.where(PXprod < 0)[0]\n",
    "    print(\"Zero-crossings (Python):\")\n",
    "    print(PXzc)\n",
    "\n",
    "    # First derivative of smoothed PX\n",
    "    PXd1 = np.gradient(PXsmth)\n",
    "    print(\"Smoothed PX (Python):\")\n",
    "    print(PXsmth)\n",
    "\n",
    "    # Find sinks\n",
    "    PXsink = [ii for ii in PXzc if PXd1[ii] < 0]\n",
    "\n",
    "    # Find sources\n",
    "    PXsrc = list(set(PXzc) - set(PXsink))\n",
    "    PXsource = [1] + PXsrc + [max(xrange)]\n",
    "    \n",
    "    # Find peaks and wells\n",
    "    peaks = []\n",
    "    wells = []\n",
    "    for ss in range(1, len(PXsource)):\n",
    "        slice_data = PXsmth[PXsource[ss - 1]:PXsource[ss]]\n",
    "        if len(slice_data) > 0:\n",
    "            valp, peak = max((val, idx) for (idx, val) in enumerate(slice_data))\n",
    "            valw, well = min((val, idx) for (idx, val) in enumerate(slice_data))\n",
    "            peaks.append(peak + PXsource[ss - 1])\n",
    "            wells.append(well + PXsource[ss - 1])\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate gaps, correlation lengths\n",
    "    gaps = np.array(wells) - np.array(peaks)\n",
    "    gaps = gaps[gaps > 0]\n",
    "    print(\"Gaps (Python):\")\n",
    "    print(gaps)\n",
    "    corr_len[i] = pxlen * np.mean(gaps)\n",
    "\n",
    "\n",
    "    np.savez(f'python/optical_flow_{tt}.npz', flow=flow)\n",
    "    np.savez(f'python/products_{tt}.npz', PX=PX, PY=PY)\n",
    "    np.savez(f'python/smoothed_PX_{tt}.npz', PXsmth=PXsmth)\n",
    "    np.savez(f'python/zero_crossings_{tt}.npz', PXzc=PXzc)\n",
    "    np.savez(f'python/gaps_{tt}.npz', gaps=gaps)\n",
    "\n",
    "# After the loop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tseries, corr_len, linewidth=5)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Correlation Length / um')\n",
    "plt.savefig('CorrLength.png')\n",
    "\n",
    "# Prepare the time values and export to a CSV file\n",
    "import pandas as pd\n",
    "\n",
    "output_data = pd.DataFrame({'Time': tseries, 'Correlation Length': corr_len})\n",
    "output_data.to_csv(sample + '_new.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "matlab_path = '/home/shichen/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/matlab/'\n",
    "python_path = '/home/shichen/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/python/'\n",
    "\n",
    "# Rest of the comparison code remains the same...\n",
    "\n",
    "\n",
    "for tt in tseries:\n",
    "    # Load data from Python\n",
    "    flow_python = np.load(f'{python_path}optical_flow_{tt}.npz')['flow']\n",
    "    products_python = np.load(f'{python_path}products_{tt}.npz')\n",
    "    smoothed_PX_python = np.load(f'{python_path}smoothed_PX_{tt}.npz')['PXsmth']\n",
    "    zero_crossings_python = np.load(f'{python_path}zero_crossings_{tt}.npz')['PXzc']\n",
    "    gaps_python = np.load(f'{python_path}gaps_{tt}.npz')['gaps']\n",
    "\n",
    "    # Load data from MATLAB\n",
    "    flow_matlab = loadmat(f'{matlab_path}optical_flow_{tt}.mat')['VV']\n",
    "    products_matlab = loadmat(f'{matlab_path}products_{tt}.mat')\n",
    "    smoothed_PX_matlab = loadmat(f'{matlab_path}smoothed_PX_{tt}.mat')['PXsmth']\n",
    "    zero_crossings_matlab = loadmat(f'{matlab_path}zero_crossings_{tt}.mat')['PXzc']\n",
    "    gaps_matlab = loadmat(f'{matlab_path}gaps_{tt}.mat')['gaps']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Compare the data\n",
    "    print(f\"Time {tt}\")\n",
    "    print(\"Flow difference: \", np.sum(np.abs(flow_python - flow_matlab)))\n",
    "    print(\"PX difference: \", np.sum(np.abs(products_python['PX'] - products_matlab['PX'])))\n",
    "    print(\"PY difference: \", np.sum(np.abs(products_python['PY'] - products_matlab['PY'])))\n",
    "    print(\"Smoothed PX difference: \", np.sum(np.abs(smoothed_PX_python - smoothed_PX_matlab)))\n",
    "    print(\"Zero crossings difference: \", np.sum(np.abs(zero_crossings_python - zero_crossings_matlab)))\n",
    "    print(\"Gaps difference: \", np.sum(np.abs(gaps_python - gaps_matlab)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of Smoothed PX (Python): \", smoothed_PX_python.shape)\n",
    "print(\"Shape of Smoothed PX (MATLAB): \", smoothed_PX_matlab.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import filters\n",
    "from scipy.ndimage import gaussian_filter, gaussian_filter1d\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initial setup\n",
    "saveimg = False\n",
    "sample = '235_MT_correlation_15ul'\n",
    "vidpath = '/home/shichen/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/'\n",
    "vidname = vidpath + sample + '.avi'\n",
    "EdgeLength = 40\n",
    "smooth = True\n",
    "smooth_len = 10\n",
    "pxlen = .43\n",
    "vscale = 1\n",
    "tmin = 10\n",
    "tmax = 100\n",
    "delta_T = 1\n",
    "step = 5\n",
    "tseries = range(tmin, tmax+1, step)\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture(vidname)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"Could not open video file {vidname}\")\n",
    "\n",
    "# Define the range of the video we are interested in\n",
    "ret, frame1 = cap.read()\n",
    "yrange = range(851, 1051)\n",
    "xrange = range(frame1.shape[1])\n",
    "\n",
    "# Initialize correlation length array\n",
    "corr_len = np.zeros(len(tseries))\n",
    "\n",
    "# Loop over the time series\n",
    "for i, tt in enumerate(tseries):\n",
    "    # Read frames tt and tt+delta_T\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt)\n",
    "    _, frame1 = cap.read()\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt+delta_T)\n",
    "    _, frame2 = cap.read()\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)[yrange, :][:, xrange]\n",
    "\n",
    "    # Normalize\n",
    "    im1 = cv2.normalize(gray1, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    im2 = cv2.normalize(gray2, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    # Convert the grayscale images to SimpleITK format\n",
    "    fixed_image = sitk.GetImageFromArray(im1)\n",
    "    moving_image = sitk.GetImageFromArray(im2)\n",
    "\n",
    "    # Perform image registration using Demons algorithm\n",
    "    demons_filter = sitk.DemonsRegistrationFilter()\n",
    "    demons_filter.SetNumberOfIterations(50)\n",
    "\n",
    "    # You can set standard deviation for Gaussian smoothing of displacement field\n",
    "    demons_filter.SetStandardDeviations(1.0)\n",
    "\n",
    "    displacement_field = demons_filter.Execute(fixed_image, moving_image)\n",
    "\n",
    "    # Convert the displacement field to a numpy array\n",
    "    displacement_field = sitk.GetArrayFromImage(displacement_field)\n",
    "\n",
    "    # Extract the velocity components\n",
    "    VX = -displacement_field[..., 0] / delta_T\n",
    "    VY = -displacement_field[..., 1] / delta_T\n",
    "\n",
    "    print(\"Displacement field (Python):\")\n",
    "    print(displacement_field)\n",
    "\n",
    "    # Apply Gaussian smoothing if desired\n",
    "    if smooth:\n",
    "        VX = filters.gaussian(VX, sigma=smooth_len)\n",
    "        VY = filters.gaussian(VY, sigma=smooth_len)\n",
    "\n",
    "    # Subtract the mean\n",
    "    VX -= VX.mean()\n",
    "    VY -= VY.mean()\n",
    "\n",
    "    # Calculate products\n",
    "    PX = im1 * VX\n",
    "    PY = im1 * VY\n",
    "    print(\"Products (Python):\")\n",
    "    print(PX)\n",
    "    print(PY)\n",
    "\n",
    "    # Compute smoothed version of PX\n",
    "    PXmean = np.mean(PX, axis=1)\n",
    "    PXsmth = gaussian_filter1d(PXmean, smooth_len)\n",
    "    PXsmth = PXsmth / np.abs(PXsmth).max()\n",
    "\n",
    "    # Find zero-crossings\n",
    "    PXprod = PXsmth[:-1] * PXsmth[1:]\n",
    "    PXzc = np.where(PXprod < 0)[0]\n",
    "    print(\"Zero-crossings (Python):\")\n",
    "    print(PXzc)\n",
    "\n",
    "    # First derivative of smoothed PX\n",
    "    PXd1 = np.gradient(PXsmth)\n",
    "    print(\"Smoothed PX (Python):\")\n",
    "    print(PXsmth)\n",
    "\n",
    "    # Find sinks\n",
    "    PXsink = [ii for ii in PXzc if PXd1[ii] < 0]\n",
    "\n",
    "    # Find sources\n",
    "    PXsrc = list(set(PXzc) - set(PXsink))\n",
    "    PXsource = [1] + PXsrc + [max(xrange)]\n",
    "    \n",
    "    # Find peaks and wells\n",
    "    peaks = []\n",
    "    wells = []\n",
    "    for ss in range(1, len(PXsource)):\n",
    "        slice_data = PXsmth[PXsource[ss - 1]:PXsource[ss]]\n",
    "        if len(slice_data) > 0:\n",
    "            valp, peak = max((val, idx) for (idx, val) in enumerate(slice_data))\n",
    "            valw, well = min((val, idx) for (idx, val) in enumerate(slice_data))\n",
    "            peaks.append(peak + PXsource[ss - 1])\n",
    "            wells.append(well + PXsource[ss - 1])\n",
    "\n",
    "    # Calculate gaps, correlation lengths\n",
    "    gaps = np.array(wells) - np.array(peaks)\n",
    "    gaps = gaps[gaps > 0]\n",
    "    print(\"Gaps (Python):\")\n",
    "    print(gaps)\n",
    "    corr_len[i] = pxlen * np.mean(gaps)\n",
    "\n",
    "    np.savez(f'python/optical_flow_{tt}.npz', flow=flow)\n",
    "    np.savez(f'python/products_{tt}.npz', PX=PX, PY=PY)\n",
    "    np.savez(f'python/smoothed_PX_{tt}.npz', PXsmth=PXsmth)\n",
    "    np.savez(f'python/zero_crossings_{tt}.npz', PXzc=PXzc)\n",
    "    np.savez(f'python/gaps_{tt}.npz', gaps=gaps)\n",
    "\n",
    "# After the loop\n",
    "plt.figure()\n",
    "plt.plot(tseries, corr_len, linewidth=5)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Correlation Length / um')\n",
    "plt.savefig('CorrLength.png')\n",
    "\n",
    "# Prepare the time values and export to a CSV file\n",
    "output_data = pd.DataFrame({'Time': tseries, 'Correlation Length': corr_len})\n",
    "output_data.to_csv(sample + '_new.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Correlation Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "import cv2\n",
    "from skimage.registration import optical_flow_tvl1\n",
    "import cupy as cp\n",
    "\n",
    "def calculate_PIV(frame1, frame2, smooth=True, smooth_len=10, delta_T=1):\n",
    "    # Convert to grayscale\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Normalize the images\n",
    "    im1 = cv2.normalize(gray1, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    im2 = cv2.normalize(gray2, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    # Compute the optical flow\n",
    "    flow = optical_flow_tvl1(im1, im2)\n",
    "    VX = -flow[..., 0] / delta_T\n",
    "    VY = -flow[..., 1] / delta_T\n",
    "\n",
    "    # Apply Gaussian smoothing if desired\n",
    "    if smooth:\n",
    "        VX = gaussian_filter(VX, sigma=smooth_len)\n",
    "        VY = gaussian_filter(VY, sigma=smooth_len)\n",
    "\n",
    "    # Subtract the mean\n",
    "    VX -= VX.mean()\n",
    "    VY -= VY.mean()\n",
    "\n",
    "    return VX, VY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cv2.cuda.getCudaEnabledDeviceCount():\n",
    "    raise Exception(\"No CUDA-enabled GPU found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cupy as cp\n",
    "from skimage.registration import optical_flow_tvl1\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sample = '235_MT_correlation_15ul'\n",
    "vidpath = '/home/shichen/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/'\n",
    "vidname = vidpath + sample + '.avi'\n",
    "delta_T = 1\n",
    "tmin = 10\n",
    "tmax = 100\n",
    "step = 5\n",
    "tseries = range(tmin, tmax+1, step)\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture(vidname)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise Exception(f\"Could not open video file {vidname}\")\n",
    "\n",
    "# Initialize the PIV data list\n",
    "piv_data = []\n",
    "\n",
    "# Create progress bar\n",
    "pbar = tqdm(total=len(tseries[:-1]))\n",
    "\n",
    "# Loop over the time series\n",
    "for i, tt in enumerate(tseries[:-1]):\n",
    "    # Read frames tt and tt+delta_T\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt)\n",
    "    _, frame1 = cap.read()\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt+delta_T)\n",
    "    _, frame2 = cap.read()\n",
    "\n",
    "    # Convert frames to grayscale if they're not already\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Transfer data to the GPU\n",
    "    gray1_gpu = cp.asarray(gray1)\n",
    "    gray2_gpu = cp.asarray(gray2)\n",
    "\n",
    "    # Compute the optical flow with the skimage function\n",
    "    # Note: skimage works on the CPU, so we need to transfer the data back from the GPU\n",
    "    flow = optical_flow_tvl1(cp.asnumpy(gray1_gpu), cp.asnumpy(gray2_gpu))\n",
    "\n",
    "    # Transfer results back to GPU memory\n",
    "    flow_gpu = cp.asarray(flow)\n",
    "    VX = flow_gpu[..., 0]\n",
    "    VY = flow_gpu[..., 1]\n",
    "\n",
    "    # Transfer results back to CPU memory and append to the data list\n",
    "    piv_data.append((cp.asnumpy(VX), cp.asnumpy(VY)))\n",
    "\n",
    "    # Update progress bar\n",
    "    pbar.update(1)\n",
    "\n",
    "# Close progress bar\n",
    "pbar.close()\n",
    "\n",
    "print(\"PIV data has been computed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first PIV data point\n",
    "VX, VY = piv_data[0]\n",
    "\n",
    "# Make a grid of points\n",
    "X, Y = np.meshgrid(np.arange(0, VX.shape[1], 1), np.arange(0, VX.shape[0], 1))\n",
    "\n",
    "# Downsample the data to make the plot manageable\n",
    "# (Adjust as needed for your data)\n",
    "X = X[::10, ::10]\n",
    "Y = Y[::10, ::10]\n",
    "VX = VX[::10, ::10]\n",
    "VY = VY[::10, ::10]\n",
    "\n",
    "# Create a quiver plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.quiver(X, Y, VX, VY, angles='xy', scale_units='xy', scale=1, width=0.005)\n",
    "plt.gca().invert_yaxis()  # invert the y-axis to match the image orientation\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_piv(frame, VX, VY, step=10):\n",
    "    # Convert frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Create a grid of points\n",
    "    y, x = np.mgrid[0:VX.shape[0], 0:VX.shape[1]]\n",
    "\n",
    "    # Plot the original frame\n",
    "    plt.imshow(frame_rgb)\n",
    "\n",
    "    # Plot the vector field\n",
    "    plt.quiver(x[::step, ::step], y[::step, ::step], VX[::step, ::step], VY[::step, ::step], color='r')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Now, let's visualize a random frame's flow field\n",
    "frame_idx = 5 # Choose an index\n",
    "\n",
    "# Read the frame at time tseries[frame_idx]\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, tseries[frame_idx])\n",
    "_, frame = cap.read()\n",
    "\n",
    "# Get the corresponding PIV data\n",
    "VX, VY = piv_data[frame_idx]\n",
    "\n",
    "# Visualize the PIV data\n",
    "visualize_piv(frame, VX, VY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Select the first PIV data point\n",
    "VX, VY = piv_data[0]\n",
    "\n",
    "# Load the first frame of the video\n",
    "cap = cv2.VideoCapture(vidname)\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "if not ret:\n",
    "    raise Exception(\"Could not load the video frame\")\n",
    "\n",
    "# Convert to grayscale for plotting\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Make a grid of points\n",
    "X, Y = np.meshgrid(np.arange(0, VX.shape[1], 1), np.arange(0, VX.shape[0], 1))\n",
    "\n",
    "# Downsample the data to make the plot manageable\n",
    "# (Adjust as needed for your data)\n",
    "X = X[::10, ::10]\n",
    "Y = Y[::10, ::10]\n",
    "VX = VX[::10, ::10]\n",
    "VY = VY[::10, ::10]\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# Display the grayscale image\n",
    "plt.imshow(gray, cmap='gray')\n",
    "\n",
    "# Overlay the quiver plot\n",
    "plt.quiver(X, Y, VX, VY, angles='xy', scale_units='xy', scale=1, width=0.005, color='r')\n",
    "plt.gca().invert_yaxis()  # invert the y-axis to match the image orientation\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# Display the grayscale image\n",
    "plt.imshow(gray, cmap='gray')\n",
    "\n",
    "# Overlay the quiver plot\n",
    "plt.quiver(X, Y, VX, VY, angles='xy', scale_units='xy', scale=0.1, width=0.005, color='r')\n",
    "plt.gca().invert_yaxis()  # invert the y-axis to match the image orientation\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the number of vectors per row and column\n",
    "num_vectors_x = VX.shape[1]\n",
    "num_vectors_y = VX.shape[0]\n",
    "\n",
    "# Create the 1D position arrays\n",
    "x_positions = np.linspace(0, gray.shape[1], num_vectors_x)\n",
    "y_positions = np.linspace(0, gray.shape[0], num_vectors_y)\n",
    "\n",
    "# Create 2D position arrays\n",
    "X, Y = np.meshgrid(x_positions, y_positions)\n",
    "\n",
    "# Now, use these 2D position arrays in your quiver plot:\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(gray, cmap='gray')\n",
    "plt.quiver(X, Y, VX, VY, angles='xy', scale_units='xy', scale=1, color='r')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "sample = '235_MT_correlation_15ul'\n",
    "vidpath = '/home/shichen/Dropbox/Academics/PhD_phase/Thompson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/'\n",
    "vidname = vidpath + sample + '.avi'\n",
    "\n",
    "cap = cv2.VideoCapture(vidname)\n",
    "ret, frame1 = cap.read()\n",
    "gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Initialize the PIV data list\n",
    "piv_data = []\n",
    "\n",
    "# Loop over the time series\n",
    "tseries = np.arange(0, 1000, 2)  # example time series\n",
    "delta_T = 1\n",
    "smooth = True\n",
    "smooth_len = 1\n",
    "\n",
    "# Create a progress bar\n",
    "pbar = tqdm(total=len(tseries[:-1]))\n",
    "\n",
    "for i, tt in enumerate(tseries[:-1]):\n",
    "    # Read frames tt and tt+delta_T\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt)\n",
    "    _, frame1 = cap.read()\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt+delta_T)\n",
    "    _, frame2 = cap.read()\n",
    "\n",
    "    # Compute the optical flow and store it in the piv_data list\n",
    "    VX, VY = calculate_PIV_gpu(frame1, frame2, smooth=smooth, smooth_len=smooth_len, delta_T=delta_T)\n",
    "    piv_data.append((VX, VY))\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# convert to numpy arrays for plotting\n",
    "VX, VY = piv_data[0]\n",
    "\n",
    "# Define the number of vectors per row and column\n",
    "num_vectors_y = VX.shape[0]\n",
    "num_vectors_x = VX.shape[1]\n",
    "\n",
    "# Create the 1D position arrays\n",
    "y_positions = np.linspace(0, gray.shape[0], num_vectors_y)\n",
    "x_positions = np.linspace(0, gray.shape[1], num_vectors_x)\n",
    "\n",
    "# Create 2D position arrays\n",
    "Y, X = np.meshgrid(y_positions, x_positions)\n",
    "\n",
    "# Now, use these 2D position arrays in your quiver plot:\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(gray, cmap='gray')\n",
    "plt.quiver(X, Y, VX.get(), VY.get(), angles='xy', scale_units='xy', scale=1, color='r')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(vidname)\n",
    "\n",
    "ret = False\n",
    "while not ret:\n",
    "    ret, frame1 = cap.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        print(\"Warning: frame not read. Trying again...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpiv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.registration import optical_flow_tvl1\n",
    "\n",
    "# Parameters\n",
    "gridSize = 30\n",
    "smooth = 1\n",
    "sigma = 30\n",
    "velScale = 1.6\n",
    "\n",
    "sample = '235_MT_correlation_15ul'\n",
    "vidpath = '/home/shichen/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/'\n",
    "vidname = vidpath + sample + '.avi'\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture(vidname)\n",
    "Ttot = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "delta_T = 1\n",
    "step = 1\n",
    "tseries = range(0, Ttot-1, step)\n",
    "\n",
    "_, im1 = cap.read()  # Read the first frame to determine the image size\n",
    "xrange = range(im1.shape[1])\n",
    "yrange = range(im1.shape[0])\n",
    "\n",
    "X1, Y1 = np.meshgrid(np.arange(gridSize/2, len(xrange)-gridSize/2, gridSize), \n",
    "                     np.arange(gridSize/2, len(yrange)-gridSize/2, gridSize))\n",
    "\n",
    "for tt in tseries:\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, tt)\n",
    "    _, im1 = cap.read()\n",
    "    _, im2 = cap.read()\n",
    "\n",
    "    im1 = im1[np.ix_(yrange, xrange)]\n",
    "    im2 = im2[np.ix_(yrange, xrange)]\n",
    "\n",
    "    # Compute PIV using optical_flow_tvl1\n",
    "    flow = optical_flow_tvl1(cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY), cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY))\n",
    "    VX = -flow[..., 0]\n",
    "    VY = -flow[..., 1]\n",
    "\n",
    "    if smooth:\n",
    "        VX = gaussian_filter(VX, sigma=sigma) / delta_T\n",
    "        VY = gaussian_filter(VY, sigma=sigma) / delta_T\n",
    "\n",
    "    UX = cv2.resize(VX, (X1.shape[1], X1.shape[0])) * velScale\n",
    "    UY = cv2.resize(VY, (X1.shape[1], X1.shape[0])) * velScale\n",
    "\n",
    "    # Visualize\n",
    "    plt.imshow(cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY), cmap='gray')\n",
    "    plt.quiver(X1, Y1, UX, UY, color='c', scale=25)\n",
    "    plt.gca().set_facecolor('black')\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ttot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate magnitude of velocity\n",
    "magnitude = np.sqrt(VX**2 + VY**2)\n",
    "\n",
    "# Display the magnitude\n",
    "plt.imshow(magnitude, cmap='viridis')\n",
    "plt.colorbar(label='Velocity Magnitude')\n",
    "plt.title(\"Magnitude of Velocity\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(VX.flatten(), bins=50)\n",
    "plt.title('Histogram of VY values')\n",
    "plt.xlabel('VY value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_vy_values = [np.mean(data[1]) for data in piv_data]\n",
    "\n",
    "plt.plot(tseries[:-1], average_vy_values)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Average VY Value')\n",
    "plt.title('Average VY value over Time')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "active_matter_amd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
