{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial autocorrelation functions\n",
    "def compute_full_product(data):\n",
    "    return np.fft.fft2(data) * np.conj(np.fft.fft2(data))\n",
    "\n",
    "def direct_spatial_autocorrelation_from_full_product(full_product, shape, r):\n",
    "    inverse = np.real(np.fft.ifft2(full_product))\n",
    "    return (inverse[r, r] + inverse[-r, -r]) / (shape[0] * shape[1])\n",
    "\n",
    "def compute_autocorrelation_for_one_time(args):\n",
    "    tt, (UX, UY), r_values = args\n",
    "    magnitude = np.sqrt(UX**2 + UY**2)\n",
    "    full_product = compute_full_product(magnitude)\n",
    "    results = [direct_spatial_autocorrelation_from_full_product(full_product, magnitude.shape, r) for r in r_values]\n",
    "    return tt, results\n",
    "\n",
    "def compute_autocorrelation_parallel(velocity_data):\n",
    "    r_values = list(range(1, 50))\n",
    "    num_processors = cpu_count()\n",
    "    args = [(tt, (UX, UY), r_values) for tt, (UX, UY) in velocity_data.items()]\n",
    "    \n",
    "    with Pool(num_processors) as pool:\n",
    "        results = pool.map(compute_autocorrelation_for_one_time, args)\n",
    "        \n",
    "    results_dict = {tt: r for tt, r in results}\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the velocity data\n",
    "file_path = '/home/shichenliu/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good/130_MT_correlation_45_1ul_new/velocity_data.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    velocity_data = pickle.load(f)\n",
    "\n",
    "# Calculate spatial autocorrelation using both methods\n",
    "direct_results_parallel = compute_autocorrelation_parallel(velocity_data)\n",
    "\n",
    "# For the purpose of this code, I'm using the same result for FFT-based results\n",
    "# You'd replace this with the actual FFT method results if you intend to compare both\n",
    "fft_results = direct_results_parallel  \n",
    "\n",
    "# Plotting results\n",
    "plt.figure(figsize=(20, 15))  # Adjusting the figure size: (width, height) in inches\n",
    "r_values = list(range(1, 50))\n",
    "for r in r_values:\n",
    "    plt.plot([direct_results_parallel[tt][r-1] for tt in sorted(direct_results_parallel.keys())], label=f\"Direct r={r}\")\n",
    "    plt.plot([fft_results[tt][r-1] for tt in sorted(fft_results.keys())], '--', label=f\"FFT r={r}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Spatial Autocorrelation')\n",
    "plt.title('Comparison of Autocorrelation Methods')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pkl_files(base_dir):\n",
    "    pkl_files = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if \"_new\" in root:\n",
    "            for file in files:\n",
    "                if file.endswith(\".pkl\"):\n",
    "                    pkl_files.append(os.path.join(root, file))\n",
    "    return pkl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_pkl_files(base_dir):\n",
    "    pkl_files = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if \"_new\" in root:\n",
    "            for file in files:\n",
    "                if file.endswith(\".pkl\"):\n",
    "                    pkl_files.append(os.path.join(root, file))\n",
    "    return pkl_files\n",
    "\n",
    "base_directory = \"/home/shichenliu/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good\"\n",
    "all_pkl_files = get_all_pkl_files(base_directory)\n",
    "\n",
    "# Define different scales and increments for r\n",
    "scales = {\n",
    "    \"microscopic\": [(2, 1), (6, 1)],\n",
    "    \"intermediate\": [(10, 5), (20, 10)]\n",
    "}\n",
    "\n",
    "for scale_name, r_dr_values in scales.items():\n",
    "    for r, dr in r_dr_values:\n",
    "        \n",
    "        plt.figure(figsize=(20, 15))  # Create a large plot\n",
    "        \n",
    "        for pkl_file in all_pkl_files:\n",
    "            \n",
    "            # Load data\n",
    "            with open(pkl_file, 'rb') as f:\n",
    "                velocity_data = pickle.load(f)\n",
    "            \n",
    "            # Compute autocorrelation\n",
    "            results_parallel = compute_autocorrelation_parallel(velocity_data)\n",
    "            \n",
    "            # Plot\n",
    "            r_values = list(range(1, 50))\n",
    "            folder_name = os.path.basename(os.path.dirname(pkl_file)).replace(\"_new\", \"\")\n",
    "            plt.plot([results_parallel[tt][r-1] if r-1 < len(results_parallel[tt]) else np.nan for tt in sorted(results_parallel.keys())], label=folder_name)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Spatial Autocorrelation')\n",
    "        plt.title(f'Autocorrelation for scale {scale_name} with r={r} and dr={dr}')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_pkl_files(base_dir):\n",
    "    pkl_files = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if \"_new\" in root:\n",
    "            for file in files:\n",
    "                if file.endswith(\".pkl\"):\n",
    "                    pkl_files.append(os.path.join(root, file))\n",
    "    return pkl_files\n",
    "\n",
    "base_directory = \"/home/shichenliu/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good\"\n",
    "all_pkl_files = get_all_pkl_files(base_directory)\n",
    "\n",
    "# Define different scales and increments for r\n",
    "scales = {\n",
    "    \"microscopic\": [(2, 1), (6, 1)],\n",
    "    \"intermediate\": [(10, 5), (20, 10)]\n",
    "}\n",
    "\n",
    "for scale_name, r_dr_values in scales.items():\n",
    "    for r, dr in r_dr_values:\n",
    "        \n",
    "        plt.figure(figsize=(20, 15))  # Create a large plot\n",
    "        \n",
    "        for pkl_file in all_pkl_files:\n",
    "            \n",
    "            # Load data\n",
    "            with open(pkl_file, 'rb') as f:\n",
    "                velocity_data = pickle.load(f)\n",
    "            \n",
    "            # Compute autocorrelation\n",
    "            results_parallel = compute_autocorrelation_parallel(velocity_data)\n",
    "            \n",
    "            # Plot\n",
    "            r_values = list(range(1, 50))\n",
    "            folder_name = os.path.basename(os.path.dirname(pkl_file)).replace(\"_new\", \"\")\n",
    "            plt.plot([results_parallel[tt][r-1] if r-1 < len(results_parallel[tt]) else np.nan for tt in sorted(results_parallel.keys())], label=folder_name)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Spatial Autocorrelation')\n",
    "        plt.title(f'Autocorrelation for scale {scale_name} with r={r} and dr={dr}')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clipped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pkl_files(base_dir):\n",
    "    pkl_files = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if \"_new\" in root:\n",
    "            for file in files:\n",
    "                if file.endswith(\".pkl\"):\n",
    "                    pkl_files.append(os.path.join(root, file))\n",
    "    return pkl_files\n",
    "\n",
    "base_directory = \"/home/shichenliu/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good\"\n",
    "all_pkl_files = get_all_pkl_files(base_directory)\n",
    "\n",
    "# Define different scales and increments for r\n",
    "scales = {\n",
    "    \"microscopic\": [(2, 1), (6, 1)],\n",
    "    \"intermediate\": [(10, 5), (20, 10)]\n",
    "}\n",
    "\n",
    "for scale_name, r_dr_values in scales.items():\n",
    "    for r, dr in r_dr_values:\n",
    "        \n",
    "        plt.figure(figsize=(20, 15))  # Create a large plot\n",
    "        \n",
    "        for pkl_file in all_pkl_files:\n",
    "            \n",
    "            # Load data\n",
    "            with open(pkl_file, 'rb') as f:\n",
    "                velocity_data = pickle.load(f)\n",
    "            \n",
    "            # Compute autocorrelation\n",
    "            results_parallel = compute_autocorrelation_parallel(velocity_data)\n",
    "            \n",
    "            # Plot\n",
    "            r_values = list(range(1, 50))\n",
    "            folder_name = os.path.basename(os.path.dirname(pkl_file)).replace(\"_new\", \"\")\n",
    "            \n",
    "            data_to_plot = [results_parallel[tt][r-1] if r-1 < len(results_parallel[tt]) else np.nan for tt in sorted(results_parallel.keys())]\n",
    "            clipped_data_to_plot = np.clip(data_to_plot, 1e-2, None)  # Clipping data here\n",
    "            \n",
    "            plt.plot(clipped_data_to_plot, label=folder_name)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Spatial Autocorrelation')\n",
    "        plt.title(f'Autocorrelation for scale {scale_name} with r={r} and dr={dr}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"/home/shichenliu/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good\"\n",
    "all_pkl_files = get_all_pkl_files(base_directory)\n",
    "\n",
    "# Define different scales and increments for r\n",
    "scales = {\n",
    "    \"microscopic\": [(2, 1), (6, 1)],\n",
    "    \"intermediate\": [(10, 5), (20, 10)]\n",
    "}\n",
    "\n",
    "for scale_name, r_dr_values in scales.items():\n",
    "    for r, dr in r_dr_values:\n",
    "        \n",
    "        plt.figure(figsize=(20, 15))  # Create a large plot\n",
    "        \n",
    "        for pkl_file in all_pkl_files:\n",
    "            \n",
    "            # Load data\n",
    "            with open(pkl_file, 'rb') as f:\n",
    "                velocity_data = pickle.load(f)\n",
    "            \n",
    "            folder_name = os.path.basename(os.path.dirname(pkl_file)).replace(\"_new\", \"\")\n",
    "            \n",
    "            # If the folder is 40_MT_2uL_correlation, clip after 60 frames\n",
    "            if folder_name == \"40_MT_2uL_correlation\":\n",
    "                velocity_data = {k: v for k, v in velocity_data.items() if k < 60}\n",
    "            if folder_name == \"40_MT_1uL_correlation\":\n",
    "                velocity_data = {k: v for k, v in velocity_data.items() if k < 60}\n",
    "            \n",
    "            # Compute autocorrelation\n",
    "            results_parallel = compute_autocorrelation_parallel(velocity_data)\n",
    "            \n",
    "            # Clip data below 10^-2\n",
    "            data_to_plot = [max(1e-2, results_parallel[tt][r-1]) if r-1 < len(results_parallel[tt]) else np.nan for tt in sorted(results_parallel.keys())]\n",
    "            \n",
    "            plt.plot(data_to_plot, label=folder_name)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Spatial Autocorrelation')\n",
    "        plt.title(f'Autocorrelation for scale {scale_name} with r={r} and dr={dr}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# ...[Your existing code for computing the autocorrelation]...\n",
    "\n",
    "# Averaging the spatial autocorrelation values over all time points\n",
    "averaged_autocorrelation = [np.mean([direct_results_parallel[tt][r-1] for tt in sorted(direct_results_parallel.keys())]) for r in r_values]\n",
    "\n",
    "# Plot the averaged values on a log-log scale\n",
    "log_r = np.log(r_values)\n",
    "log_averaged_autocorrelation = np.log(averaged_autocorrelation)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(log_r, log_averaged_autocorrelation, c='blue', label='Averaged Data')\n",
    "\n",
    "# Perform linear regression on the log-transformed values\n",
    "slope, intercept, r_value, _, _ = linregress(log_r, log_averaged_autocorrelation)\n",
    "plt.plot(log_r, intercept + slope*log_r, 'r', label=f'Fitted line with slope={slope:.2f}')\n",
    "plt.title(f'Log-log plot with R^2 = {r_value**2:.3f}')\n",
    "plt.xlabel('log(r)')\n",
    "plt.ylabel('log(Averaged Spatial Autocorrelation)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pkl_files(base_dir):\n",
    "    pkl_files = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if \"_new\" in root:\n",
    "            for file in files:\n",
    "                if file.endswith(\".pkl\"):\n",
    "                    pkl_files.append(os.path.join(root, file))\n",
    "    return pkl_files\n",
    "\n",
    "def compute_vorticity(UX, UY):\n",
    "    dVY_dx = np.gradient(UY, axis=1)\n",
    "    dUX_dy = np.gradient(UX, axis=0)\n",
    "    return dVY_dx - dUX_dy\n",
    "\n",
    "def mean_subtracted_velocity_correlation(UX, UY, r):\n",
    "    mean_UX = np.mean(UX)\n",
    "    mean_UY = np.mean(UY)\n",
    "    UX_dev = UX - mean_UX\n",
    "    UY_dev = UY - mean_UY\n",
    "    correlation = (UX_dev * np.roll(UX_dev, shift=-r, axis=1)) + (UY_dev * np.roll(UY_dev, shift=-r, axis=0))\n",
    "    return np.mean(correlation)\n",
    "\n",
    "def angular_velocity_correlation(omega, r):\n",
    "    correlation = omega * np.roll(omega, shift=-r, axis=1)\n",
    "    return np.mean(correlation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"/home/shichenliu/Dropbox/Academics/PhD_phase/Thomson_Lab/local_to_global_pre-print/data/figure_1/correlation_good\"\n",
    "all_pkl_files = get_all_pkl_files(base_directory)\n",
    "\n",
    "r_values = list(range(1, 50))\n",
    "\n",
    "# Plotting Mean-Subtracted Velocity Correlation for all experiments\n",
    "plt.figure(figsize=(20, 15))\n",
    "for pkl_file in all_pkl_files:\n",
    "    with open(pkl_file, 'rb') as f:\n",
    "        velocity_data = pickle.load(f)\n",
    "    \n",
    "    avg_UX = np.mean([data[0] for data in velocity_data.values()], axis=0)\n",
    "    avg_UY = np.mean([data[1] for data in velocity_data.values()], axis=0)\n",
    "\n",
    "    mean_subtracted_vals = [mean_subtracted_velocity_correlation(avg_UX, avg_UY, r) for r in r_values]\n",
    "    plt.plot(r_values, mean_subtracted_vals, label=os.path.basename(os.path.dirname(pkl_file)).replace(\"_new\", \"\"))\n",
    "\n",
    "plt.xlabel('r')\n",
    "plt.ylabel('Mean-Subtracted Velocity Correlation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting Angular Velocity Correlation for all experiments\n",
    "plt.figure(figsize=(20, 15))\n",
    "for pkl_file in all_pkl_files:\n",
    "    with open(pkl_file, 'rb') as f:\n",
    "        velocity_data = pickle.load(f)\n",
    "    \n",
    "    avg_UX = np.mean([data[0] for data in velocity_data.values()], axis=0)\n",
    "    avg_UY = np.mean([data[1] for data in velocity_data.values()], axis=0)\n",
    "    omega = compute_vorticity(avg_UX, avg_UY)\n",
    "\n",
    "    angular_vals = [angular_velocity_correlation(omega, r) for r in r_values]\n",
    "    plt.plot(r_values, angular_vals, label=os.path.basename(os.path.dirname(pkl_file)).replace(\"_new\", \"\"))\n",
    "\n",
    "plt.xlabel('r')\n",
    "plt.ylabel('Angular Velocity Correlation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "active_matter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
